# -*- coding: utf-8 -*-
"""EfficientNetnetipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j3MmhBJ71U3bpdW6QxlPUZ7AXMweaMSQ
"""

from google.colab import drive
drive.mount('/content/drive')

import os

# Path to the ZIP file
zip_path = "/content/drive/MyDrive/arch-20250122T141841Z-001.zip"  # Update with your actual file path
extract_path = "/content/dataset"  # Target directory for extraction

# Unzip the file
os.system(f"unzip -q {zip_path} -d {extract_path}")
print(f"âœ… Dataset extracted to: {extract_path}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0, MobileNetV2
from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
import numpy as np

# Define dataset path
dataset_path = "/content/dataset/arch"

# Image settings
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32

# Data Augmentation & Loading
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training')

val_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation')

# Number of classes
num_classes = len(train_generator.class_indices)

# Function to create models
def create_model(base_model):
    base_model.trainable = False  # Freeze the convolutional base
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(128, activation='relu')(x)
    output = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=base_model.input, outputs=output)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Define models
models = {

    "EfficientNet": create_model(EfficientNetB0(weights='imagenet', include_top=False, input_shape=IMAGE_SIZE + (3,))),

}

# Training all models
history_dict = {}
for name, model in models.items():
    print(f"Training {name}...")
    history = model.fit(train_generator, validation_data=val_generator, epochs=10)
    model.save(f"{name}_model.h5")
    history_dict[name] = history

# Plot accuracy comparison
plt.figure(figsize=(12, 6))
for name, history in history_dict.items():
    plt.plot(history.history['accuracy'], label=f'{name} Train')
    plt.plot(history.history['val_accuracy'], label=f'{name} Val')
plt.title('Model Accuracy Comparison')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Evaluate models
for name, model in models.items():
    loss, accuracy = model.evaluate(val_generator)
    print(f"{name} - Accuracy: {accuracy * 100:.2f}% | Loss: {loss:.4f}")

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image

# Function to load and preprocess the image
def preprocess_image(image_path, target_size=(224, 224)):
    img = image.load_img(image_path, target_size=target_size)  # Resize to match model input
    img_array = image.img_to_array(img)  # Convert to array
    img_array = np.expand_dims(img_array, axis=0)  # Expand dims for batch size
    img_array = img_array / 255.0  # Normalize pixel values
    return img_array, img

# Function to make predictions with a given model
def make_prediction(model, img_array):
    predictions = model.predict(img_array)
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    confidence = np.max(predictions) * 100  # Confidence percentage
    return predicted_class_index, confidence

# Define the models you trained
models = {

    "EfficientNet": tf.keras.models.load_model("/content/EfficientNet_model.h5"),

}

# Path to the test image
image_path = "/content/dataset/arch/Die Back/20211129_160425 (Custom).jpg"  # Update with your test image path

# Preprocess the image
img_array, img = preprocess_image(image_path)

# Get class labels from the training generator
class_labels = list(train_generator.class_indices.keys())

# Dictionary to store predictions and confidences
predictions_dict = {}

# Iterate through all models and make predictions
for model_name, model in models.items():
    print(f"Testing model: {model_name}...")

    # Make prediction
    predicted_class_index, confidence = make_prediction(model, img_array)

    # Get the predicted class name
    predicted_class_name = class_labels[predicted_class_index]

    # Store the prediction and confidence
    predictions_dict[model_name] = {
        "predicted_class": predicted_class_name,
        "confidence": confidence
    }

    # Display the result for each model
    print(f"{model_name} - Predicted Class: {predicted_class_name}, Confidence: {confidence:.2f}%")

    # Display the image with prediction
    plt.figure(figsize=(6, 6))
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"{model_name} Predicted: {predicted_class_name}\nConfidence: {confidence:.2f}%")
    plt.show()

# Final output of all models' predictions
print("\nAll Models' Predictions:")
for model_name, result in predictions_dict.items():
    print(f"{model_name} - Predicted Class: {result['predicted_class']}, Confidence: {result['confidence']:.2f}%")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming `test_generator` contains the test dataset
# test_generator is prepared similar to train_generator with ImageDataGenerator
test_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',  # Use the validation set for evaluation
    shuffle=False  # Keep data in order for proper evaluation
)

# Extract true labels and predictions
y_true = test_generator.classes  # Ground truth labels
class_labels = list(test_generator.class_indices.keys())  # Class label names

# Initialize a dictionary to store metrics for each model
metrics_dict = {}

for model_name, model in models.items():
    print(f"Evaluating {model_name}...")

    # Get predictions from the model
    y_pred_probs = model.predict(test_generator)  # Predict probabilities
    y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class indices

    # Accuracy
    accuracy = accuracy_score(y_true, y_pred)

    # Precision, Recall, F1 Score (weighted for imbalanced datasets)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    # Store metrics
    metrics_dict[model_name] = {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1
    }

    # Print Classification Report
    print(f"\n{model_name} Classification Report:")
    print(classification_report(y_true, y_pred, target_names=class_labels))

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
    plt.title(f"{model_name} Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

# Output the collected metrics for all models
print("\nAll Models' Metrics:")
for model_name, metrics in metrics_dict.items():
    print(f"\n{model_name}:")
    print(f"  - Accuracy: {metrics['accuracy'] * 100:.2f}%")
    print(f"  - Precision (Weighted): {metrics['precision']:.4f}")
    print(f"  - Recall (Weighted): {metrics['recall']:.4f}")
    print(f"  - F1-Score (Weighted): {metrics['f1_score']:.4f}")